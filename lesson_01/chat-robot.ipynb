{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问题一：英文版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def is_variable(pat):\n",
    "    return pat.startswith('?') and all(s.isalpha() for s in pat[1:])\n",
    "\n",
    "def pat_to_dict(patterns):\n",
    "    return {k: ' '.join(v) if isinstance(v, list) else v for k, v in patterns}\n",
    "\n",
    "\n",
    "def is_pattern_segment(pattern):\n",
    "    return pattern.startswith('?*') and all(a.isalpha() for a in pattern[2:])\n",
    "\n",
    "def subsitite(rule, parsed_rules):\n",
    "    if not rule: return []\n",
    "    return [parsed_rules.get(rule[0], rule[0])] + subsitite(rule[1:], parsed_rules)\n",
    "\n",
    "fail = [True, None]\n",
    "\n",
    "def pat_match_with_seg(pattern, saying):\n",
    "    if not pattern or not saying: return []\n",
    "    pat = pattern[0]\n",
    "    if is_variable(pat):\n",
    "        return [(pat, saying[0])] + pat_match_with_seg(pattern[1:], saying[1:])\n",
    "    elif is_pattern_segment(pat):\n",
    "        match, index = segment_match(pattern, saying)\n",
    "        return [match] + pat_match_with_seg(pattern[1:],saying[index:])\n",
    "    elif pat == saying[0]:\n",
    "        return pat_match_with_seg(pattern[1:], saying[1:])\n",
    "    else:\n",
    "        return fail\n",
    "\n",
    "def segment_match(pattern, saying):\n",
    "    seg_pat, rest = pattern[0], pattern[1:]\n",
    "    seg_pat = seg_pat.replace('?*', '?')\n",
    "    if not rest: return (seg_pat, saying), len(saying)  \n",
    "    for i, token in enumerate(saying):\n",
    "        if rest[0] == token and is_match(rest[1:], saying[(i + 1):]):\n",
    "            return (seg_pat, saying[:i]), i\n",
    "    return (seg_pat, saying), len(saying) \n",
    "\n",
    "def is_match(rest, saying):\n",
    "    if not rest and not saying:\n",
    "        return True\n",
    "    if not all(a.isalpha() for a in rest[0]):\n",
    "        return True\n",
    "    if rest[0] != saying[0]:\n",
    "        return False\n",
    "    return is_match(rest[1:], saying[1:])\n",
    "\n",
    "def response(saying,rule_responses):\n",
    "    for key in rule_responses.keys():\n",
    "        get_pattern = pat_match_with_seg(key.split(),saying.split())\n",
    "        #get_pattern = pat_match(key.split(),saying.split())\n",
    "        if len(get_pattern[0][1]) != len(saying.split()):\n",
    "            rs_answer = random.choice(rule_responses[key])\n",
    "            ls_answer = subsitite(rs_answer.split(), pat_to_dict(get_pattern))\n",
    "            return ' '.join(ls_answer)\n",
    "    print(\"I don't know what you mean?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what would it mean if you got to go to school'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enrule_responses = { '?*x hello ?*y': ['How do you do', 'Please state your problem'],\n",
    "    '?*x I want ?*y': ['what would it mean if you got ?y', 'Why do you want ?y', 'Suppose you got ?y soon'],\n",
    "    '?*x if ?*y': ['Do you really think its likely that ?y', 'Do you wish that ?y', 'What do you think about ?y', 'Really-- if ?y'],\n",
    "    '?*x no ?*y': ['why not?', 'You are being a negative', 'Are you saying \\'No\\' just to be negative?'],\n",
    "    '?*x I was ?*y': ['Were you really', 'Perhaps I already knew you were ?y', 'Why do you tell me you were ?y now?'],\n",
    "    '?*x I feel ?*y': ['Do you often feel ?y ?', 'What other feelings do you have?']}\n",
    "response(\"today I want to go to school\",enrule_responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问题二 支持中文和英文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import jieba\n",
    "from collections import defaultdict\n",
    "fail = [True, None]\n",
    "\n",
    "def is_variable(pat):\n",
    "    return pat.startswith('?') and all(s.isalpha() for s in pat[1:])\n",
    "\n",
    "def pat_to_dict(patterns):\n",
    "    return {k: ' '.join(v) if isinstance(v, list) else v for k, v in patterns}\n",
    "\n",
    "def is_pattern_segment(pattern):\n",
    "    return pattern.startswith('?*') and all(a.isalpha() for a in pattern[2:])\n",
    "\n",
    "def subsitite(rule, parsed_rules):\n",
    "    if not rule: return []\n",
    "    return [parsed_rules.get(rule[0], rule[0])] + subsitite(rule[1:], parsed_rules)\n",
    "\n",
    "def pat_match_with_seg(pattern, saying):\n",
    "    if not pattern or not saying: return []\n",
    "    pat = pattern[0]\n",
    "    if is_variable(pat):\n",
    "        return [(pat, saying[0])] + pat_match_with_seg(pattern[1:], saying[1:])\n",
    "    elif is_pattern_segment(pat):\n",
    "        match, index = segment_match(pattern, saying)\n",
    "        return [match] + pat_match_with_seg(pattern[1:],saying[index:])\n",
    "    elif pat == saying[0]:\n",
    "        return pat_match_with_seg(pattern[1:], saying[1:])\n",
    "    else:\n",
    "        return fail\n",
    "\n",
    "def segment_match(pattern, saying):\n",
    "    seg_pat, rest = pattern[0], pattern[1:]\n",
    "    seg_pat = seg_pat.replace('?*', '?')\n",
    "    if not rest: return (seg_pat, saying), len(saying)\n",
    "    for i, token in enumerate(saying):\n",
    "        if rest[0] == token and is_match(rest[1:], saying[(i + 1):]):\n",
    "            return (seg_pat, saying[:i]), i\n",
    "    return (seg_pat, saying), len(saying)\n",
    "\n",
    "def is_match(rest, saying):\n",
    "    if not rest and not saying:\n",
    "        return True\n",
    "    if not all(a.isalpha() for a in rest[0]):\n",
    "        return True\n",
    "    if rest[0] != saying[0]:\n",
    "        return False\n",
    "    return is_match(rest[1:], saying[1:])\n",
    "\n",
    "def have_chinese(check_str):\n",
    "    \"\"\"\n",
    "    判断字符串中是否包含中文\n",
    "    :param check_str: {str} 需要检测的字符串\n",
    "    :return: {bool} 包含返回True， 不包含返回False\n",
    "    \"\"\"\n",
    "    for ch in check_str:\n",
    "        if u'\\u4e00' <= ch <= u'\\u9fff':\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_pat(pat):\n",
    "    if have_chinese(pat):#判断是否含中文\n",
    "        seg = list(jieba.cut(pat))\n",
    "        ls=[]\n",
    "        temp = []\n",
    "        for ele in seg:\n",
    "            if ele == '?' and temp ==[]:\n",
    "                temp.append(ele)\n",
    "            elif not have_chinese(ele) and temp !=[]:\n",
    "                temp.append(ele)\n",
    "            elif have_chinese(ele) and temp != []:\n",
    "                ls.append(''.join(temp))\n",
    "                ls.append(ele)\n",
    "                temp = []\n",
    "            else:\n",
    "                ls.append(ele)\n",
    "        if temp !=[]:ls.append(''.join(temp))\n",
    "        return ls\n",
    "    else:#不含中文的情况\n",
    "        return pat.split()\n",
    "\n",
    "def roughly_match(pat,saying):\n",
    "    '''如果saying中不存在pat中的模板次（非?*x变量词），返回False'''\n",
    "    for ele in pat:\n",
    "        if have_chinese(ele) and ele not in saying:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def response2(saying,rule_responses):\n",
    "    for key in rule_responses.keys():\n",
    "        if roughly_match(get_pat(key),get_pat(saying)):\n",
    "            get_pattern = pat_match_with_seg(get_pat(key),get_pat(saying))\n",
    "            #get_pattern = pat_match(key.split(),saying.split())\n",
    "            if len(get_pattern[0][1]) != len(get_pat(saying)):\n",
    "                random_answer = random.choice(rule_responses[key])\n",
    "                parse_answer = subsitite(get_pat(random_answer), pat_to_dict(get_pattern))\n",
    "                if have_chinese(parse_answer):#由于中文和英文返回的字符串拼接方式不一样，加个判断是否为中文或英文answer\n",
    "                    parse_answer = ''.join(parse_answer)\n",
    "                    parse_answer = parse_answer.replace(' ','')\n",
    "                    return parse_answer\n",
    "                else:\n",
    "                    return ' '.join(parse_answer)\n",
    "        else:\n",
    "            continue\n",
    "    return (''.join(random.choice(rule_responses['?*x'])))#如果无匹配成功的，返回rule_response中的未匹配key [“?*x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'其实很有可能我们互相觉得'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule_responses = {\n",
    "    '?*x hello ?*y': ['How do you do', 'Please state your problem'],\n",
    "    '?*x I want ?*y': ['what would it mean if you got ?y', 'Why do you want ?y', 'Suppose you got ?y soon'],\n",
    "    '?*x if ?*y': ['Do you really think its likely that ?y', 'Do you wish that ?y', 'What do you think about ?y', 'Really-- if ?y'],\n",
    "    '?*x no ?*y': ['why not?', 'You are being a negative', 'Are you saying \\'No\\' just to be negative?'],\n",
    "    '?*x I was ?*y': ['Were you really', 'Perhaps I already knew you were ?y', 'Why do you tell me you were ?y now?'],\n",
    "    '?*x I feel ?*y': ['Do you often feel ?y ?', 'What other feelings do you have?'],\n",
    "    '?*x你好?*y': ['你好呀', '请告诉我你的问题'],\n",
    "    '?*x我想?*y': ['你觉得?y有什么意义呢？', '为什么你想?y', '你可以想想你很快就可以?y了'],\n",
    "    '?*x我想要?*y': ['?x想问你，你觉得?y有什么意义呢?', '为什么你想?y', '?x觉得... 你可以想想你很快就可以有?y了', '你看?x像?y不', '我看你就像?y'],\n",
    "    '?*x喜欢?*y': ['喜欢?y的哪里？', '?y有什么好的呢？', '你想要?y吗？'],\n",
    "    '?*x讨厌?*y': ['?y怎么会那么讨厌呢?', '讨厌?y的哪里？', '?y有什么不好呢？', '你不想要?y吗？'],\n",
    "    '?*x AI? *y': ['你为什么要提AI的事情？', '你为什么觉得AI要解决你的问题？'],\n",
    "    '?*x机器人?*y': ['你为什么要提机器人的事情？', '你为什么觉得机器人要解决你的问题？'],\n",
    "    '?*x对不起?*y': ['不用道歉', '你为什么觉得你需要道歉呢?'],\n",
    "    '?*x我记得?*y': ['你经常会想起这个吗？', '除了?y你还会想起什么吗？', '你为什么和我提起?y'],\n",
    "    '?*x如果?*y': ['你真的觉得?y会发生吗？', '你希望?y吗?', '真的吗？如果?y的话', '关于?y你怎么想？'],\n",
    "    '?*x我?*z梦见?*y':['真的吗? --- ?y', '你在醒着的时候，以前想象过?y吗？', '你以前梦见过?y吗'],\n",
    "    '?*x妈妈?*y': ['你家里除了?y还有谁?', '嗯嗯，多说一点和你家里有关系的', '她对你影响很大吗？'],\n",
    "    '?*x爸爸?*y': ['你家里除了?y还有谁?', '嗯嗯，多说一点和你家里有关系的', '他对你影响很大吗？', '每当你想起你爸爸的时候， 你还会想起其他的吗?'],\n",
    "    '?*x我愿意?*y': ['我可以帮你?y吗？', '你可以解释一下，为什么想?y'],\n",
    "    '?*x我很难过，因为?*y': ['我听到你这么说， 也很难过', '?y不应该让你这么难过的'],\n",
    "    '?*x难过?*y': ['我听到你这么说， 也很难过',\n",
    "                 '不应该让你这么难过的，你觉得你拥有什么，就会不难过?',\n",
    "                 '你觉得事情变成什么样，你就不难过了?'],\n",
    "    '?*x就像?*y': ['你觉得?x和?y有什么相似性？', '?x和?y真的有关系吗？', '怎么说？'],\n",
    "    '?*x和?*y都?*z': ['你觉得?z有什么问题吗?', '?z会对你有什么影响呢?'],\n",
    "    '?*x和?*y一样?*z': ['你觉得?z有什么问题吗?', '?z会对你有什么影响呢?'],\n",
    "    '?*x我是?*y': ['真的吗？', '?x想告诉你，或许我早就知道你是?y', '你为什么现在才告诉我你是?y'],\n",
    "    '?*x我是?*y吗': ['如果你是?y会怎么样呢？', '你觉得你是?y吗', '如果你是?y，那一位着什么?'],\n",
    "    '?*x你是?*y吗':  ['你为什么会对我是不是?y感兴趣?', '那你希望我是?y吗', '你要是喜欢， 我就会是?y'],\n",
    "    '?*x你是?*y' : ['为什么你觉得我是?y'],\n",
    "    '?*x因为?*y' : ['?y是真正的原因吗？', '你觉得会有其他原因吗?'],\n",
    "    '?*x我不能?*y': ['你或许现在就能?*y', '如果你能?*y,会怎样呢？'],\n",
    "    '?*x我觉得?*y': ['你经常这样感觉吗？', '除了到这个，你还有什么其他的感觉吗？'],\n",
    "    '?*x我?*y你?*z': ['其实很有可能我们互相?y'],\n",
    "    '?*x你为什么不?*y': ['你自己为什么不?y', '你觉得我不会?y', '等我心情好了，我就?y'],\n",
    "    '?*x好的?*y': ['好的', '你是一个很正能量的人'],\n",
    "    '?*x嗯嗯?*y': ['好的', '你是一个很正能量的人'],\n",
    "    '?*x不嘛?*y': ['为什么不？', '你有一点负能量', '你说 不，是想表达不想的意思吗？'],\n",
    "    '?*x不要?*y': ['为什么不？', '你有一点负能量', '你说 不，是想表达不想的意思吗？'],\n",
    "    '?*x有些人?*y': ['具体是哪些人呢?'],\n",
    "    '?*x有的人?*y': ['具体是哪些人呢?'],\n",
    "    '?*x某些人?*y': ['具体是哪些人呢?'],\n",
    "    '?*x每个人?*y': ['我确定不是人人都是', '你能想到一点特殊情况吗？', '例如谁？', '你看到的其实只是一小部分人'],\n",
    "    '?*x所有人?*y': ['我确定不是人人都是', '你能想到一点特殊情况吗？', '例如谁？', '你看到的其实只是一小部分人'],\n",
    "    '?*x总是?*y': ['你能想到一些其他情况吗?', '例如什么时候?', '你具体是说哪一次？', '真的---总是吗？'],\n",
    "    '?*x一直?*y': ['你能想到一些其他情况吗?', '例如什么时候?', '你具体是说哪一次？', '真的---总是吗？'],\n",
    "    '?*x或许?*y': ['你看起来不太确定'],\n",
    "    '?*x可能?*y': ['你看起来不太确定'],\n",
    "    '?*x他们是?*y吗？': ['你觉得他们可能不是?y？'],\n",
    "    '?*x': ['很有趣', '请继续', '我不太确定我很理解你说的, 能稍微详细解释一下吗?']\n",
    "}\n",
    "response2('今天我觉得你很棒',rule_responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问题三"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "多设计一些模式，让这个程序变得更好玩，多和大家交流，看看大家有什么好玩的模式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问题四\n",
    "\n",
    "### 1.这样的程序有什么优点？有什么缺点？你有什么可以改进的方法吗？\n",
    "我觉的这样的程序如果再改进一下，能解决一些日常常识型的问题，比如一些基于事实或者有点类似于检索的问答都可以这样做。\n",
    "但是它的缺点也很明显，一是基于纯基于检索的问答，不灵活，如果出现没有定义在数据模板中的问句，就无法回答，所以如果想要覆盖面大，需要巨大的数据支撑。二，它是没有思想的，一切都是基于检索，并没有自己的思\n",
    "对于如何改进，使用基于知识图谱的问答,看到github中挺多基于知识图谱的问答项目，虽然在问答时也是基于检索的，但是构图的过程可以看成一个学习的过程，我觉得这种方式有一定的思想；基于NLP技术的问答，通常将问句与数据库中的问句进行相似度计算，这样做会更加灵活。\n",
    "对于改进的方法，\n",
    "### 2.什么是数据驱动？数据驱动在这个程序里如何体现？\n",
    "数据驱动，我觉得就是我们做的是从数据出发的，感觉就比如，用神经网络训练模型，是模型是从数据中学习得到，这个过程我觉得就像数据驱动\n",
    "然后这个程序的体现，我认为是在回答的内容时基于你问的内容，而不是你预先定义好的。比如我喜欢苹果，根据预定义模板，可以回答你为什么喜欢苹果，但是苹果事先并没有并预定义，而是来自你问的问题中，这就是数据驱动\n",
    "### 3.数据驱动与 AI 的关系是什么？\n",
    "数据驱动与AI的关系，就如我上面说的，AI是从数据中学习的。之前看到过一段话，put more emphasis on making data adapt to model rather than constructing a model to match the real world. （配图）原来你说的早点睡是吃了早点再睡。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
